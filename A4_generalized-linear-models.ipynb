{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Crash course 4: Generalized linear models</center>\n",
    "\n",
    "### <center>Alfred Galichon (NYU & Sciences Po)</center>\n",
    "## <center>'math+econ+code' masterclass on optimal transport and economic applications</center>\n",
    "#### <center>With python code examples</center>\n",
    "© 2018-2022 by Alfred Galichon. Past and present support from NSF grant DMS-1716489, ERC grant CoG-866274 are acknowledged, as well as inputs from contributors listed [here](http://www.math-econ-code.org/theteam).\n",
    "\n",
    "**If you reuse material from this masterclass, please cite as:**<br>\n",
    "Alfred Galichon, 'math+econ+code' masterclass on optimal transport and economic applications, January 2022. https://github.com/math-econ-code/mec_optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* McCullagh and Nelder (1989). Generalized Linear Models (2nd ed.). Chapman and Hall/CRC.\n",
    "* Friedman, Tibshirani, and Hastie (2001). The Elements of Statistical Learning. Springer.\n",
    "* The Scikit-learn library www.scikit-learn.org.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized linear models\n",
    "## Setting\n",
    "\n",
    "* In many setting, an economic model will allow to make predictions on the\n",
    "conditional mean of a dependent random variable $\\mu_a$ given explanatory random\n",
    "vector $\\phi_a$, for observations $a\\in\\mathcal{A}$.\n",
    "\n",
    "* In the case of linear regression, we have<br>\n",
    "$E\\left[  \\mu_a | \\phi_a \\right]  =\\phi_a^{\\top}\\beta$<br>\n",
    "however, we shall encounter situations where it will be useful to be more general.\n",
    "\n",
    "* This leads us to *generalized linear models* (GLM), which are specified as<br>\n",
    "$E\\left[  \\mu_a|\\phi_a\\right]  =g^{-1}\\left(  \\phi_a^{\\top}\\beta\\right)$<br>\n",
    "where $g:\\mathbb{R}\\rightarrow\\mathbb{R}$ is an increasing and continuous function called *link function*, and $\\beta \\in \\mathbb{R}^K$.\n",
    "\n",
    "* Often we shall specify in addition $Var\\left(  \\mu_a |\\phi_a \\right)  =V\\left(\n",
    "g^{-1}\\left(  \\phi_a^{\\top}\\beta\\right)  \\right)  $.\n",
    "\n",
    "We shall use `linear_model`from the scikit-learn library `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Example 1: ordinary least squares (OLS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* In least squares (OLS), we have<br>\n",
    "$\\mu_a=\\phi_a^{\\top}\\beta+\\epsilon_a$<br>\n",
    "with $E\\left[  \\epsilon_a|\\phi_a\\right]  =0$, in which case $g\\left(  z\\right)  =z$.\n",
    "\n",
    "* Additionally, assuming $E\\left[  \\epsilon_a^{2}|\\phi \\right]  =\\sigma^{2}$, we\n",
    "have<br>\n",
    "$Var\\left(  \\mu_a|\\phi_a\\right)  =\\sigma^{2}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS regression in scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "nba,nbk = 100,10\n",
    "np.random.seed(7)\n",
    "Φ_a_k = np.random.randn(nba,nbk)\n",
    "μ_a = np.random.randn(nba)\n",
    "ols = linear_model.LinearRegression()\n",
    "ols.fit (Φ_a_k, μ_a)\n",
    "ols.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Poisson regression\n",
    "\n",
    "\n",
    "\n",
    "* Recall a Poisson distribution with parameter $\\theta\\in(0,+\\infty)$ has\n",
    "probability mass<br>\n",
    "$\\Pr(\\mu|\\theta)=\\frac{e^{-\\theta}\\theta^{\\mu}}{\\mu!}$<br>\n",
    "over $\\mu \\in\\left\\{  0,1,2,...\\right\\}  $. It has expectation and variance\n",
    "$\\theta$.\n",
    "\n",
    "* Assume that conditional on $\\phi_a$, $\\mu_a$ has a Poisson distribution of\n",
    "parameter $\\mu^\\beta_a=\\exp\\left(  \\phi_a^{\\top}\\beta\\right)  $. Then<br>\n",
    "$ E\\left[  \\mu_a|\\phi_a\\right]  =\\exp\\left(  \\phi_a^{\\top}\\beta\\right)$<br>\n",
    "so in this case $g=\\ln$.\n",
    "\n",
    "* Note that we get<br>\n",
    "$var\\left(  \\mu_a|\\phi_a\\right)  =\\exp\\left(  \\phi_a^{\\top}\\beta\\right)$<br>\n",
    "which may be overrestrictive (more on this later).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson regression\n",
    "\n",
    "\n",
    "\n",
    "* Sample log-likelihood:<br>\n",
    "$\n",
    "\\sum_{a}-\\exp\\left(  \\phi_{a}^{\\top}\\beta\\right)  + \\phi_{a}^{\\top}\\beta \\hat{\\mu}_a -\\ln\\left(  \\hat{\\mu}_a!\\right)\n",
    "$<br>\n",
    "and therefore, max likelihood yields the Poisson regression<br>\n",
    "$\n",
    "\\max_{\\beta}\\left\\{ \\sum_{a} \\hat{\\mu}_a \\phi_{a}^{\\top}\\beta  -\\sum_{a}\\exp\\left(  \\phi_{a}^{\\top}\\beta\\right)\\right\\}\n",
    "$<br>\n",
    "\n",
    "* First order conditions give<br>\n",
    "$\n",
    "\\sum_{a}\\left(  \\hat{\\mu}_a-\\exp\\left(  \\phi_{a}^{\\top}\\beta\\right)  \\right)  \\phi_{ak}=0.\n",
    "$<br>\n",
    "and therefore $\\beta$ is obtained by matching the predicted moments with the\n",
    "observed ones<br>\n",
    "$\n",
    "\\mathbb{E}_\\beta\\left[ \\phi_k \\right]  =\\hat{\\mathbb{E}}\\left[ \\phi_k \\right]  .\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson regression in scikit-learn\n",
    "\n",
    "The following example is taken from the `scikit-learn` documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PoissonRegressor.html\n",
    "\n",
    "\n",
    "Φ_a_k = [[1, 2], [2, 3], [3, 4], [4, 3]]\n",
    "μ_a = [12, 17, 22, 21]\n",
    "poisson = linear_model.PoissonRegressor()\n",
    "poisson.fit(Φ_a_k, μ_a)\n",
    "print('Score       = ', poisson.score(Φ_a_k, μ_a))\n",
    "print('Coef        = ', poisson.coef_)\n",
    "print('Intercept   = ', poisson.intercept_)\n",
    "print('Predictions = ', poisson.predict([[1, 1], [3, 4]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML inference in Poisson regression (ctd)\n",
    "\n",
    "\n",
    "* Recall that if $E_{P_{n}}\\log P \\left(  \\beta,\\mu\\right)  $ is the\n",
    "log-likelihood of the sample, and setting $l\\left(  \\beta,\\mu\\right)  =\\log\n",
    "P\\left(  \\beta,\\mu\\right)  $ we get\n",
    "\n",
    "$$\n",
    "E_{P_{n}}\\left[  \\partial_{\\beta}l\\left(  \\beta_{n},\\mu\\right)  \\right]   \n",
    "=0\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "E_{P}\\left[  \\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\right]     =0\n",
    "$$\n",
    "\n",
    "thus\n",
    "$E_{P}\\left[  \\partial_{\\beta}l\\left(  \\beta_{n},\\mu\\right)  \\right]\n",
    "-E_{P}\\left[  \\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\right]  =E_{P}\\left[\n",
    "\\partial_{\\beta}l\\left(  \\beta_{n},\\mu\\right)  \\right]  -E_{P_{n}}\\left[\n",
    "\\partial_{\\beta}l\\left(  \\beta_{n},\\mu\\right)  \\right]\n",
    "$\n",
    "therefore\n",
    "\n",
    "$$\n",
    "\\left(  \\beta_{n}-\\beta\\right)  E_{P}\\left[  \\partial_{\\beta}^{2}l\\left(\n",
    "\\beta_{n},\\mu\\right)  \\right]  =-\\frac{1}{\\sqrt{n}}g_{n}\\left(  \\partial_{\\beta\n",
    "}l\\left(  \\beta,\\mu\\right)  \\right)\n",
    "$$\n",
    "where $g_{n}f=\\sqrt{n}\\left(  E_{P_{n}}f-E_{P}f\\right)$.\n",
    "\n",
    "* Thus\n",
    "$$\n",
    "\\beta_{n}-\\beta=-\\frac{1}{\\sqrt{n}}\\left(  E_{P}\\left[  \\partial_{\\beta}%\n",
    "^{2}l\\left(  \\beta,\\mu\\right)  \\right]  \\right)  ^{-1}g_{n}\\left(\n",
    "\\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "* Hence\n",
    "$$\n",
    "V \\left(\\beta_{n}-\\beta\\right)   =\\frac{1}{n}\\left(  E_{P}\\left[\n",
    "\\partial_{\\beta}^{2}l\\left(  \\beta,\\mu\\right)  \\right]  \\right)  ^{-1}  \\times E_{P}\\left(  \\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\left(\n",
    "\\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\right)  ^{\\top}\\right)  \\times\\left(  E_{P}\\left[  \\partial_{\\beta}^{2}l\\left(  \\beta,\\mu\\right)\n",
    "\\right]  \\right)  ^{-1}\n",
    "$$\n",
    "\n",
    "\n",
    "* And because at the ML parameter\n",
    "$$\n",
    "E_{P}\\left(  \\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\left(  \\partial_{\\beta\n",
    "}l\\left(  \\beta,\\mu\\right)  \\right)  ^{\\top}\\right)  =E_{P}\\left[\n",
    "\\partial_{\\beta}^{2}l\\left(  \\beta,\\mu\\right)  \\right]  ,\n",
    "$$\n",
    "we have thus\n",
    "$$\n",
    "V\\left(  \\beta_{n}-\\beta\\right)  =\\frac{1}{n}\\left(  E_{P}\\left[\n",
    "\\partial_{\\beta}^{2}l\\left(  \\beta,\\mu\\right)  \\right]  \\right)  ^{-1}.\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation of GLM\n",
    "\n",
    "\n",
    "\n",
    "* Actually, we don't need to assume that $\\mu_a | \\phi_a \\sim Poisson\\left(\n",
    "\\exp(\\phi_a^{\\top}\\beta)\\right)  $ to estimate $\\beta$.\n",
    "\n",
    "* Consider $\\Phi$ the $\\mathcal{A} \\times K$ matrix obtained by stacking the rows $\\phi_{a}^{\\top}$ on\n",
    "top of each other. Compute<br>\n",
    "$\n",
    "\\max_{\\beta}\\left\\{  \\hat{\\mu}^{\\top}\\Phi \\beta-1_\\mathcal{A}^{\\top}\\exp\\left(  (\\Phi \\beta)_a\\right)\n",
    "\\right\\}\n",
    "$<br>\n",
    "and define $\\mu^\\beta=\\exp\\left(  \\Phi \\beta\\right)  $ the predictor of $\\mu$.\n",
    "One has<br>\n",
    "$\n",
    "\\sum_{a}\\hat{\\mu}_{a}\\Phi_{ak}=\\sum_{a}\\mu^\\beta_{a}\\Phi_{ak}~\\forall k\n",
    "$<br>\n",
    "and therefore $\\beta$ is obtained by the same procedure as before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference in GLM\n",
    "\n",
    "\n",
    "* While the point estimate is unchanged wrt the Poisson regression, the\n",
    "inference is changed as soon as one departs from the assumption that\n",
    "$Var\\left(  \\mu_a | \\phi_a \\right)  =\\exp(\\phi_a^{\\top}\\beta)$. Denote this quantity by  $V\\left(  \\mu | \\phi \\right) $.\n",
    "\n",
    "* The estimation of $\\beta$ is now seen as what is called an *M-estimation* procedure<br>\n",
    "$\n",
    "\\max_{\\beta} \\sum_{a\\in\\mathcal{A} }F\\left(  \\mu_a,\\beta \\right)  .\n",
    "$\n",
    "\n",
    "\n",
    "* The derivation done for MLE applies replacing $\\partial_{\\beta}l\\left(\n",
    "\\beta,\\mu_a\\right)  =\\partial_{\\beta}\\log P\\left(  \\beta,\\mu_a\\right)  $ by\n",
    "$\\partial_{\\beta}l\\left(  \\beta,\\mu_a\\right)  =\\left(  \\mu_a-\\exp\\left(\n",
    "\\phi_a^{\\top}\\beta\\right)  \\right)  \\phi_a$ with the provision that\n",
    "$E_{P}\\left[  \\partial_{\\beta}^{2}l\\left(  \\beta,\\mu\\right)  \\right]  \\neq\n",
    "E_{P}\\left[  \\partial l\\left(  \\beta,\\mu\\right)  \\partial l\\left(\n",
    "\\beta,\\mu\\right)  ^{\\top}\\right]  $. Hence\n",
    "\n",
    "$$\n",
    "V\\left(  \\beta_{n}-\\beta\\right)   =\\frac{1}{n}\\left(  E_{P}\\left[\n",
    "\\partial_{\\beta}^{2}l\\left(  \\beta,\\mu\\right)  \\right]  \\right)  ^{-1} \\times E_{P}\\left(  \\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\left(\n",
    "\\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\right)  ^{\\top}\\right) \\times\\left(  E_{P}\\left[  \\partial_{\\beta}^{2}l\\left(  \\beta,\\mu\\right)\n",
    "\\right]  \\right)  ^{-1}%\n",
    "$$\n",
    "\n",
    "* We have<br>\n",
    "$\n",
    "E_{P}\\left[  \\partial_{\\beta}^{2}l\\left(  \\beta,\\mu\\right)  \\right]  =E\\left[\n",
    "\\exp\\left(  \\phi^{\\top}\\beta\\right)  \\phi \\phi^{\\top}\\right]\n",
    "$<br>\n",
    "and\n",
    "\n",
    "$$\n",
    "E_{P}\\left[  \\partial_{\\beta}l\\left(  \\beta,\\mu\\right)  \\left(  \\partial_{\\beta\n",
    "}l\\left(  \\beta,\\mu\\right)  \\right)  ^{\\top}\\right]  =E\\left[  \\left(\n",
    "\\mu-\\exp\\left(  \\phi^{\\top}\\beta\\right)  \\right)  ^{2}\\phi \\phi^{\\top}\\right] \\\\  =E\\left[  V\\left(  \\mu | \\phi \\right)  \\phi \\phi^{\\top}\\right]  .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson regression and duality\n",
    "\n",
    "\n",
    "Consider $\\mu \\in\\mathbb{R}_{+}^{\\mathcal{A} }$, $\\beta\\in \\mathbb{R}^{k}$ and $\\Phi$ a $\\mathcal{A}\\times k$ matrix\n",
    "\n",
    "\n",
    "> <span style=\"color:yellow\"> **Theorem (Poisson duality)**. The primal problem\n",
    "$$\n",
    "\\max_{\\beta}\\left\\{ \\hat{ \\mu }^{\\top}\\Phi \\beta-1_\\mathbb{A}^{\\top}\\exp\\left(  \\Phi\\beta\\right)\n",
    "\\right\\}\n",
    "$$\n",
    "has dual\n",
    "$$\n",
    "\\min_{\\bar{\\mu}\\in\\mathbb{R}_{+}^{\\mathcal{A}}}  \\bar{\\mu}^{\\top}\\left(  \\ln\\bar\n",
    "{\\mu}-1\\right) \\\\\n",
    "s.t.   \\Phi^{\\top}\\left(  \\hat{\\mu} -\\bar{\\mu}\\right)  =0.\n",
    "$$</span>\n",
    "\n",
    "\n",
    "**Proof**. Start from the latter expression and write the Lagrangian for\n",
    "the problem \n",
    "\n",
    "$$\n",
    "\\min_{\\bar{\\mu}\\geq0}\\max_{\\beta}\\bar{\\mu}^{\\top}\\left(  \\ln\\bar{\\mu}-1\\right)\n",
    "-\\left(  \\bar{\\mu}-\\hat{\\mu} \\right)  ^{\\top}\\Phi\\beta =\\max_{\\beta} \\hat{\\mu}^{\\top}\\Phi\\beta+\\min_{\\bar{\\mu}\\geq0}\\left\\{  \\bar{\\mu}^{\\top\n",
    "}\\left(  \\ln\\bar{\\mu}-1\\right)  -\\bar{\\mu}^{\\top}\\Phi\\beta\\right\\}\n",
    "$$\n",
    "\n",
    "has $\\ln\\bar{\\mu}=\\Phi\\beta$ and $\\bar{\\mu}^{\\top}\\left(  \\ln\\bar{\\mu}-1\\right)\n",
    "-\\bar{\\mu}^{\\top}\\Phi\\beta=-\\bar{\\mu}^{\\top}1=-1^{\\top}\\exp\\left(  \\Phi\\beta\\right)  $\n",
    "and hence this is\n",
    "\n",
    "$$\n",
    "\\max_{\\beta} \\hat{\\mu}^{\\top}\\Phi\\beta-1_\\mathcal{A}^{\\top}\\exp\\left(  \\Phi\\beta\\right)  .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete choice models\n",
    "\n",
    "## Multinomial logit model\n",
    "\n",
    "\n",
    "* Now assume that the observations are $\\mathcal{A} = \\mathcal{I} \\times \\mathcal{Y}$ where $\\mathcal{I}$ is the set of decision-makers and $\\mathcal{Y}$ is the set of alternatives. Consider the logit model where the utility that $i$ assigns to choice $y$ is\n",
    "$$\n",
    "\\sum_{k}\\Phi_{iy}^{k}\\beta_{k}+\\varepsilon_{iy}$$\n",
    "where $\\varepsilon_{iy}$ are iid Gumbel distributions, i.e. of c.d.f.\n",
    "$\\exp\\left(  -\\exp\\left(  -x\\right)  \\right)  $.\n",
    "\n",
    "* The conditional probability that $i$ chooses $y$ is\n",
    "$$\n",
    "\\mu^\\beta_{iy}=\\frac{\\exp\\left(  \\sum_{k}\\Phi_{iy}^{k}\\beta_{k}\\right)  }{\\sum\n",
    "_{y}\\exp\\left(  \\sum_{k}\\Phi_{iy}^{k}\\beta_{k}\\right)  }\n",
    "$$\n",
    "and therefore the conditional likelihood associated with $y$ is<br>\n",
    "$\n",
    "l_{iy}\\left(  \\beta\\right)  =\\log \\mu^\\beta_{iy}=\\sum_{k}\\Phi_{iy}^{k}\\beta\n",
    "_{k}-\\log\\sum_{y}\\exp\\left(  \\sum_{k}\\Phi_{iy}^{k}\\beta_{k}\\right)\n",
    "$\n",
    "\n",
    "* As a result, if $y\\left(  i\\right)  $ is the actual choice of $i$, and\n",
    "$\\hat{\\mu}_{iy}=1\\left\\{  y=y\\left(  i\\right)  \\right\\}  $, the logistic\n",
    "regression can be expressed as\n",
    "\n",
    "$$\n",
    "l\\left(  \\beta\\right)  =\\hat{\\mu}^{\\top}\\Phi\\beta-\\sum_{i}\\log\\sum_{y}%\n",
    "\\exp\\left(  \\left(  \\Phi\\beta\\right)  _{iy}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "* This is *almost*, but *not quite* the form of a GLM $-$ notice\n",
    "the $\\log$. To make the precise connection with GLM/Poisson regression, we\n",
    "need to introduce *individual fixed effects*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regresssion as a Poisson regression+individual fixed effects\n",
    "\n",
    "\n",
    "* Introduce a fixed effect $u_{i}$ and let $\\theta=\\left(  \\beta^{\\top\n",
    "},u^{\\top}\\right)  ^{\\top}$. We rewrite $\\left(  \\beta,u\\right)\n",
    "\\rightarrow\\left(  \\left(  \\Phi\\beta\\right)  _{iy}-u_{i}\\right)  _{iy}$ in a\n",
    "matrix form by defining\n",
    "\n",
    "$$\n",
    "X=%\n",
    "\\begin{pmatrix}\n",
    "\\Phi, - M_\\mathcal{I}^\\top%\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "where $M_\\mathcal{I} = I_{\\mathcal{I} }\\otimes 1^\\top_{\\mathcal{Y}}$ is the MOM (margining- out matrix) on the first dimension, and we have\n",
    "$$\n",
    "(X\\theta)_{iy}=  \\left(  \\Phi\\beta\\right)  _{iy}-u_{i}.\n",
    "$$\n",
    "\n",
    "\n",
    "* The Poisson regression of $\\hat{\\mu}_{iy}$ on $X$ yields\n",
    "$$\n",
    "\\max_{\\beta,u}\\left\\{  -\\sum_{iy}\\exp\\left(  \\left(  \\Phi\\beta\\right)\n",
    "_{iy}-u_{i}\\right)  +\\sum_{iy}\\hat{\\mu}_{iy}\\left(  \\left(  \\Phi\n",
    "\\beta\\right)  _{iy}-u_{i}\\right)  \\right\\}\n",
    "$$\n",
    "therefore\n",
    "$$\n",
    "\\max_{\\beta_k,u_i}\\left\\{  -\\sum_{iy}\\exp\\left(  \\left(  \\Phi\\beta\\right)\n",
    "_{iy}-u_{i}\\right)  +\\sum_{iy}\\hat{\\mu}_{iy}\\left(  \\Phi\\beta\\right)\n",
    "_{iy}-\\sum_{i}u_{i}\\right\\}. \n",
    "$$\n",
    "\n",
    "* Taking first order conditions in $u_{i}$ we get\n",
    "$$\n",
    "\\sum_{y}\\exp\\left(  \\left(  \\Phi\\beta\\right)  _{iy}-u_{i}\\right)  =1\n",
    "$$\n",
    "\n",
    "\n",
    "* Therefore, $u_{i}=\\log\\sum_{y}\\exp\\left(  \\left(  \\Phi\\beta\\right)\n",
    "_{iy}\\right)  $ and the problem becomes the **logistic regression**\n",
    "model\n",
    "$$\n",
    "\\max_{\\beta_k}\\left\\{  \\sum_{iy}\\hat{\\mu}_{iy}\\left(  \\Phi\\beta\\right)\n",
    "_{iy}-\\sum_{i}\\log\\sum_{y}\\exp\\left(  \\left(  \\Phi\\beta\\right)\n",
    "_{iy}\\right)  \\right\\}  .\n",
    "$$\n",
    "\n",
    "\n",
    "* To summarize: \n",
    "> <span style=\"color:yellow\">**Logistic regression = GLM + fixed effect**.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial logit model in scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as spr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbi,nby,nbk = 100,4,6\n",
    "nba = nbi*nby\n",
    "np.random.seed(7)\n",
    "y_i = np.random.randint(0,nby,nbi)\n",
    "μ_i_y = spr.csr_matrix( (np.ones(nbi), (range(nbi), y_i ))).todense()\n",
    "μ_a = μ_i_y.reshape((-1,1))\n",
    "Φ_a_k = np.random.randn(nba,nbk)\n",
    "X_a_l = spr.hstack([spr.kron(spr.identity(nbi), np.ones((nby,1))), -Φ_a_k])\n",
    "logistic_as_poisson = linear_model.PoissonRegressor(fit_intercept=False)\n",
    "logistic_as_poisson.fit(X_a_l, μ_a)\n",
    "print('β_k = ', logistic_as_poisson.coef_[:nbk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade models\n",
    "\n",
    "## Gravity equation\n",
    "\n",
    "\n",
    "* The gravity models seeks to explain the trade flows $\\hat{\\mu}_{xy}$\n",
    "from country $x$ to country $y$ by using various measures of proximity between\n",
    "these countries. (We assume $\\hat{\\mu}_{xx}=0$.)\n",
    "\n",
    "* We denote\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{array} \\\\\n",
    "n_x=\\sum_{y}\\hat{\\mu}_{xy}\\\\\n",
    "m_y=\\sum_{x}\\hat{\\mu}_{xy}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "the total volume of the exports of country $x$ and of the imports of country\n",
    "$y$, respectively.\n",
    "\n",
    "* We have the accounting equation\n",
    "$$\n",
    "\\sum_{x}n_x=\\sum_{xy}\\hat{\\mu}_{xy}=\\sum_{y}m_y%\n",
    "$$\n",
    "and (by simply rescaling) we can without loss of generality assume that these\n",
    "quantities sum to one.\n",
    "\n",
    "* The *gravity model* assumes\n",
    "$$\n",
    "E\\left[  \\hat{\\mu}_{xy}|\\Phi\\right]  =\\exp\\left(  \\left(  \\Phi\\lambda\\right)\n",
    "_{xy}-u_{x}-v_{y}\\right)\n",
    "$$\n",
    "\n",
    "where $u_{x}$ and $v_{y}$ are resistance terms, or country-specific fixed\n",
    "effects. This is a GLM with two-way fixed effects. Need to rewrite $\\left(\n",
    "\\lambda,u,v\\right)  \\rightarrow\\left(  \\left(  \\Phi\\lambda\\right)  _{xy}%\n",
    "-u_{x}-v_{y}\\right)  _{xy}$ in a matrix form, again using vectorization and\n",
    "Kronecker products.\n",
    "\n",
    "* Hence:\n",
    "> <span style=\"color:yellow\">**Gravity equation = GLM + 2-ways fixed effect** </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed effects and Kronecker products\n",
    "\n",
    "\n",
    "* Set up\n",
    "$$\n",
    "X=%\n",
    "\\begin{pmatrix}\n",
    "\\Phi & - M_\\mathcal{X}^\\top & -M_\\mathcal{Y}^\\top\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "where $M_\\mathcal{X} = I_{\\mathcal{X} }\\otimes 1^\\top_{\\mathcal{Y}}$ and  $M_\\mathcal{Y} = 1^\\top_{\\mathcal{Y}} \\otimes I_{\\mathcal{X}} $ are the MOM matrices on the first and the second margins respectively.\n",
    "\n",
    "* Taking parameter $\\theta=\\left(  \\beta^{\\top},u^{\\top},v^{\\top}\\right)\n",
    "^{\\top}$, we have\n",
    "$$\n",
    "X\\theta=vec\\left(  \\left(  \\left(  \\Phi\\beta\\right)  _{xy}-u_{x}%\n",
    "-v_{y}\\right)  _{xy}\\right)  .\n",
    "$$\n",
    "\n",
    "\n",
    "* Therefore rewrite our regression with dependent variable $\\hat{\\mu}_{xy}$, and\n",
    "consider the Poisson regression\n",
    "\n",
    "$$\n",
    "\\max_{\\theta}\\left\\{  \\hat{\\mu}^{\\top}X\\theta-1^{\\top}\\exp\\left(  X\\theta\\right)\n",
    "\\right\\}\n",
    "$$\n",
    "which becomes\n",
    "$$\n",
    "\\max_{\\beta,u,v}\\left\\{  \\sum_{xy}\\hat{\\mu}_{xy}\\left(  \\left(  \\Phi\n",
    "\\beta\\right)  _{xy}-u_{x}-v_{y}\\right)  -\\sum_{xy}\\exp\\left(  \\left(\n",
    "\\Phi\\beta\\right)  _{xy}-u_{x}-v_{y}\\right)  \\right\\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gravity as max-entropy\n",
    "\n",
    "\n",
    "* By the GLM duality theorem, the dual to this program is\n",
    "$$ \\min_{\\mu_{xy}\\geq0}\\sum_{xy}\\mu_{xy}\\ln\\mu_{xy}-\\sum_{xy}\\mu_{xy}\\\\\n",
    "s.t.~ \\sum_y\\mu_{xy}=n_x,~\\sum_x\\mu_{xy}=m_y\\\\\n",
    " \\sum_{xy}\\mu_{xy}\\Phi_{xy}^{k}=\\sum_{xy}\\hat{\\mu}_{xy}\\Phi_{xy}^{k}\n",
    "$$\n",
    "\n",
    "* But as $\\sum_{xy}\\mu_{xy}=1$, we interpret the previous program as\n",
    "looking among the $\\mu_{xy}$ that has the same margins and moments as\n",
    "$\\hat{\\mu}$, the one that maximizes entropy $-\\sum_{xy}\\mu_{xy}\\ln\\mu_{xy}$.\n",
    "Rewrite as\n",
    "\n",
    "$$\n",
    "\\max_{\\mu_{xy}\\geq0}\\left\\{  -\\sum_{xy}\\mu_{xy}\\ln\\mu_{xy}\\right\\} \\\\\n",
    "s.t.~  \\sum_y\\mu_{xy}=n_x,~\\sum_x\\mu_{xy}=m_y\\\\\n",
    "\\sum_{xy}\\mu_{xy}\\Phi_{xy}^{k}=\\sum_{xy}\\hat{\\mu}_{xy}\\Phi_{xy}^{k}%\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching models\n",
    "\n",
    "\n",
    "* Becker (1973) describes the following model of the labor market, the\n",
    "marriage market, and other matching markets. Consider a population with a\n",
    "share $n_x$ men of type $i$ and a share $m_y$ of women of type $j$,\n",
    "assuming that men and women come in equal numbers. Assume that if $i$ and $j$\n",
    "match, this generates a joint surplus (sum of their utilities) $\\Phi_{xy}$.\n",
    "\n",
    "\n",
    "* Let $\\mu_{xy}$ be the fraction of couples $xy$ that are formed at\n",
    "equilibrium. Becker shows that the equilibrium maximizes the total surplus\n",
    "$\\sum_{xy}\\mu_{xy}\\Phi_{xy}$ out of all the feasible matchings, which are\n",
    "those with\n",
    "$$\n",
    "\\sum_{j}\\mu_{xy}=n_x\\text{ and }\\sum_{i}\\mu_{xy}=m_y.\n",
    "$$\n",
    "\n",
    "* Therefore, the equilibrium matching $\\mu_{xy}$ should solve\n",
    "$$\n",
    "\\max_{\\mu_{xy}\\geq0} \\sum_{xy}\\mu_{xy}\\Phi_{xy}\\\\\n",
    "s.t.~  \\sum_{j}\\mu_{xy}=n_x\\text{ and }\\sum_{i}\\mu_{xy}=m_y.\n",
    "$$\n",
    "\n",
    "* Choo and Siow (2006) and Dupuy and Galichon (2015) consider a variant\n",
    "of this model with entropic regularization\n",
    "\n",
    "$$\n",
    "\\max_{\\mu_{xy}\\geq0} \\sum_{xy}\\mu_{xy}\\Phi_{xy}-\\sigma\\sum_{xy}\\mu_{xy}%\n",
    "\\ln\\mu_{xy}\\\\\n",
    "s.t.~  \\sum_{j}\\mu_{xy}=n_x\\text{ and }\\sum_{i}\\mu_{xy}=m_y.\n",
    "$$\n",
    "\n",
    "\n",
    "* We shall see that we can parametrically estimate $\\Phi$ in this model by\n",
    "the same tools as for the gravity equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to gravity equation\n",
    "\n",
    "\n",
    "* Consider the previous program\n",
    "$$ \\max_{\\mu_{xy}\\geq0}\\left\\{  -\\sum_{xy}\\mu_{xy}\\ln\\mu_{xy}\\right\\} \\\\\n",
    "s.t.~ \\sum_y\\mu_{xy}=n_x,~\\sum_x\\mu_{xy}=m_y\\\\\n",
    " \\sum_{xy}\\mu_{xy}\\Phi_{xy}^{k}=\\sum_{xy}\\hat{\\mu}_{xy}\\Phi_{xy}^{k}%\n",
    "$$\n",
    "\n",
    "and rewrite as\n",
    "$$\n",
    "\\max_{\\mu_{xy}\\geq0}\\left\\{  -\\sum_{xy}\\mu_{xy}\\ln\\mu_{xy}+\\min_{\\left(\n",
    "\\lambda_{k}\\right)  }\\left\\{  \\sum_{xy\n",
    "k}\\left(  \\mu_{xy}-\\hat{\\mu}%\n",
    "_{xy}\\right)  \\Phi_{xy}^{k}\\lambda_{k}\\right\\}  \\right\\} \\\\\n",
    "s.t.~ \\sum_y\\mu_{xy}=n_x,~\\sum_x\\mu_{xy}=m_y%\n",
    "$$\n",
    "\n",
    "* By the strong duality theorem, this is\n",
    "$$\n",
    "\\min_{\\left(  \\lambda_{k}\\right)  }\\left\\{  W\\left(  \\beta\\right)  -\\sum\n",
    "_{xyk}\\hat{\\mu}_{xy}\\Phi_{xy}^{k}\\lambda_{k}\\right\\}\n",
    "$$\n",
    "where we recover\n",
    "$$\n",
    "W\\left(  \\beta\\right)  =\\max_{\\mu_{xy}\\geq0} \\left\\{  \\sum_{xyk}\\mu\n",
    "_{xy}\\Phi_{xy}^{k}\\lambda_{k}-\\sum_{xy}\\mu_{xy}\\ln\\mu_{xy}\\right\\} \\\\\n",
    "s.t.~ \\sum_y\\mu_{xy}=n_x,~\\sum_x\\mu_{xy}=m_y%\n",
    "$$\n",
    "which is the matching surplus.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
